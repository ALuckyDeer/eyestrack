# eyestrack

忘了加.gitignore

曾经学习的一个视线跟踪代码

由py2.7升级到了py3.7

原理是先用opencv内置的检测器识别到脸和眼

得到眼睛的的元组之后，分别计算瞳孔中心的概率估计

根据瞳孔和眼框的相对位置与鼠标点击的位置进行最小二乘训练

十几次之后能得到一个大概的位置

论文地址忘了，里面附加了斯坦福学生的paper

---
# 未来改进方向
* 使用深度学习的方法来增强识别的鲁棒性，解决瞳孔识别率不高、戴眼镜反光，瞳孔位置丢失等问题
* 可以加入部分的三维重建，计算头部的旋转与眼睛和瞳孔位置的关系，因为单纯的计算眼框和瞳孔的相对位置结果比较死板，头部稍微抖动一点就不准确了，还需要重新不断地点击鼠标和移动眼睛来训练
* `对颈部以下瘫痪的患者来说加入头部移动计算没用，但是对正常人来说有用，这算两种方向`
